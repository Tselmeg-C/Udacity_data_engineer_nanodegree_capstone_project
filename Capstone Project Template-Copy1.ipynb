{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering for Analysis on i94Immigration Data from US\n",
    "### Udacity Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project, I worked with four datasets from different sources, designed a Star Schema for those data and prepared them ready for interested analysis on immigration to USA. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession,Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "I will start from exploring the raw datasets, loading, checking size, schema, columns etc. and find out the connections between tables and do necessary cleanings. Then I will design a Star Schema for the datasets which is fit to the analytical purpose and selecting columns and join them to create the fact and dimension tables and save them back to the cloud cluster. Data will be processed mainly with PySpark and the final tables will be stored back to the cloud cluster as parquet files.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "\n",
    "The following datasets are included in the project. \n",
    "\n",
    "**I94 Immigration Data**: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. [This](https://travel.trade.gov/research/reports/i94/historical/2016.html) is where the data comes from.     \n",
    "**World Temperature Data**: This dataset came from Kaggle. Read more about it [here](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).            \n",
    "**U.S. City Demographic Data**: This data comes from OpenSoft. Read more about it [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).   \n",
    "\n",
    "**Airport Code Table**: This is a simple table of airport codes and corresponding cities. It comes from [here](https://datahub.io/core/airport-codes#data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\t# creating sparksession \n",
    "spark = SparkSession.builder.\\\n",
    "                    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\"). \\\n",
    "                    enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.1 I94 Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load i94immigration data from local\n",
    "df_sas =spark.read.format('com.github.saurfang.sas.spark') \\\n",
    "            .load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "#write to parquet\n",
    "#df_sas.write.parquet(\"sas_data\")\n",
    "# read in parquet files\n",
    "df_sas=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check columns\n",
    "df_sas.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "|5748519.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20582.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     M|  null|     DL|9.495640653E10|00040|      B1|\n",
      "|5748520.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  29.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1987.0|10292016|     F|  null|     DL|9.495645143E10|00040|      B1|\n",
      "|5748521.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     WA|20588.0|  28.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1988.0|10292016|     M|  null|     DL|9.495638813E10|00040|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show first 5 rows\n",
    "df_sas.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "|airline|i94port|i94addr|\n",
      "+-------+-------+-------+\n",
      "|ZZ     |MIA    |NC     |\n",
      "|ZZ     |WAS    |NY     |\n",
      "|ZZ     |SEA    |WA     |\n",
      "|ZZ     |SFR    |DE     |\n",
      "|ZZ     |NYC    |NJ     |\n",
      "|ZZ     |ADW    |null   |\n",
      "|ZZ     |SFR    |NY     |\n",
      "|ZZ     |MIA    |FL     |\n",
      "|ZZ     |BRO    |TX     |\n",
      "|ZZ     |NYC    |CT     |\n",
      "|ZZ     |ATL    |NY     |\n",
      "|ZZ     |NEW    |HI     |\n",
      "|ZZ     |ADW    |MD     |\n",
      "|ZZ     |NYC    |NY     |\n",
      "|ZZ     |HHW    |HI     |\n",
      "|ZX     |WAS    |IN     |\n",
      "|ZX     |FTL    |MN     |\n",
      "|ZX     |TOR    |GA     |\n",
      "|ZX     |FTL    |OH     |\n",
      "|ZX     |HHW    |CT     |\n",
      "+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore columns \n",
    "df_sas.select(col('airline'),col('i94port'),col('i94addr')).distinct().sort(df_sas.airline.desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count rows\n",
    "df_sas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|  occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender| insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|   802|      0|    0|       1| 1881250|3088187|    238| 138429|3095921| 138429|    802|    477|414269|2982605|  83627|     0|19549|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get count of both null and missing values\n",
    "df_sas.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_sas.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df_sas.dropDuplicates()\n",
    "df_sas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert SAS date to spark datetype, change column names and types, drop columns\n",
    "df_sas = df_sas.withColumn(\"data_base_sas\", to_date(lit(\"01/01/1960\"), \"MM/dd/yyyy\")) \\\n",
    "            .withColumn(\"arrival_date\", expr(\"date_add(data_base_sas, arrdate)\")) \\\n",
    "            .withColumn(\"departure_date\", expr(\"date_add(data_base_sas, depdate)\")) \\\n",
    "            .drop(\"data_base_sas\", \"arrdate\", \"depdate\") \\\n",
    "            .withColumn(\"cic_id\",col(\"cicid\").cast(IntegerType())).drop(\"cicid\") \\\n",
    "            .withColumn(\"arrive_year\",col('i94yr').cast(IntegerType())).drop(\"i94yr\") \\\n",
    "            .withColumn(\"arrive_month\",col('i94mon').cast(IntegerType())).drop(\"i94mon\") \\\n",
    "            .withColumn(\"citizen_country\",col('i94cit').cast(IntegerType())).drop(\"i94cit\") \\\n",
    "            .withColumn(\"resident_country\",col('i94res').cast(IntegerType())).drop(\"i94res\") \\\n",
    "            .withColumn(\"age\",col('i94bir').cast(IntegerType())).drop(\"i94bir\") \\\n",
    "            .withColumn(\"birth_year\",col('biryear').cast(IntegerType())).drop(\"biryear\") \\\n",
    "            .withColumn(\"visa_class\",col('i94visa').cast(IntegerType())).drop(\"i94visa\") \\\n",
    "            .withColumn(\"mode\",col('i94mode').cast(IntegerType())).drop(\"i94mode\") \\\n",
    "            .withColumn(\"allowed_date\", to_date(\"dtaddto\", \"MMddyyyy\")) \\\n",
    "            .withColumnRenamed(\"i94port\", \"port\") \\\n",
    "            .withColumnRenamed(\"i94addr\",\"arrive_state\") \\\n",
    "            .withColumnRenamed(\"visapost\",\"visa_issue_state\") \\\n",
    "            .withColumnRenamed(\"entdepa\",\"arrive_flag\") \\\n",
    "            .withColumnRenamed(\"entdepd\",\"departure_flag\") \\\n",
    "            .withColumnRenamed(\"matflag\",\"match_flag\") \\\n",
    "            .withColumnRenamed(\"entdepu\",\"update_flag\") \\\n",
    "            .withColumnRenamed(\"fltno\",\"flight_num\") \\\n",
    "            .withColumnRenamed(\"visatype\",\"visa_type\") \\\n",
    "            .withColumnRenamed(\"visapost\",\"visa_issue_state\") \\\n",
    "            .withColumnRenamed(\"occup\",\"occupation\") \\\n",
    "            .drop('count','dtadfile','insnum','admnum','dtaddto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- port: string (nullable = true)\n",
      " |-- arrive_state: string (nullable = true)\n",
      " |-- visa_issue_state: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- arrive_flag: string (nullable = true)\n",
      " |-- departure_flag: string (nullable = true)\n",
      " |-- update_flag: string (nullable = true)\n",
      " |-- match_flag: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_num: string (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- cic_id: integer (nullable = true)\n",
      " |-- arrive_year: integer (nullable = true)\n",
      " |-- arrive_month: integer (nullable = true)\n",
      " |-- citizen_country: integer (nullable = true)\n",
      " |-- resident_country: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- visa_class: integer (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- allowed_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sas.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+----------------+----------+-----------+--------------+-----------+----------+------+-------+----------+---------+------------+--------------+-------+-----------+------------+---------------+----------------+---+----------+----------+----+------------+\n",
      "|port|arrive_state|visa_issue_state|occupation|arrive_flag|departure_flag|update_flag|match_flag|gender|airline|flight_num|visa_type|arrival_date|departure_date| cic_id|arrive_year|arrive_month|citizen_country|resident_country|age|birth_year|visa_class|mode|allowed_date|\n",
      "+----+------------+----------------+----------+-----------+--------------+-----------+----------+------+-------+----------+---------+------------+--------------+-------+-----------+------------+---------------+----------------+---+----------+----------+----+------------+\n",
      "| LOS|          CA|             SYD|      null|          G|             O|       null|         M|     F|     QF|     00011|       B1|  2016-04-30|    2016-05-08|5748517|       2016|           4|            245|             438| 40|      1976|         1|   1|  2016-10-29|\n",
      "| LOS|          NV|             SYD|      null|          G|             O|       null|         M|     F|     VA|     00007|       B1|  2016-04-30|    2016-05-17|5748518|       2016|           4|            245|             438| 32|      1984|         1|   1|  2016-10-29|\n",
      "| LOS|          WA|             SYD|      null|          G|             O|       null|         M|     M|     DL|     00040|       B1|  2016-04-30|    2016-05-08|5748519|       2016|           4|            245|             438| 29|      1987|         1|   1|  2016-10-29|\n",
      "| LOS|          WA|             SYD|      null|          G|             O|       null|         M|     F|     DL|     00040|       B1|  2016-04-30|    2016-05-14|5748520|       2016|           4|            245|             438| 29|      1987|         1|   1|  2016-10-29|\n",
      "| LOS|          WA|             SYD|      null|          G|             O|       null|         M|     M|     DL|     00040|       B1|  2016-04-30|    2016-05-14|5748521|       2016|           4|            245|             438| 28|      1988|         1|   1|  2016-10-29|\n",
      "+----+------------+----------------+----------+-----------+--------------+-----------+----------+------+-------+----------+---------+------------+--------------+-------+-----------+------------+---------------+----------------+---+----------+----------+----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show first 5 rows\n",
    "df_sas.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist\n",
    "if (os.path.exists(\"file:/home/workspace/immigration\")\n",
    "    os.rmdir(\"file:/home/workspace/immigration\")\n",
    "else:\n",
    "# write to parquet\n",
    "    df_sas.write.partitionBy('arrive_state').parquet('immigration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.2 U.S. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load us-cities-demographics.csv\n",
    "df_demo = spark.read.csv(\"us-cities-demographics.csv\",header=True,sep=\";\")\n",
    "df_demo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo.printSchema()\n",
    "df_demo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- median_age: float (nullable = true)\n",
      " |-- male_population: integer (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- total_population: integer (nullable = true)\n",
      " |-- veterans_num: integer (nullable = true)\n",
      " |-- foreign_born_population: integer (nullable = true)\n",
      " |-- avg_household_size: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change datatypes, format column names and delete duplicates\n",
    "df_demo = df_demo.withColumn(\"median_age\",col(\"Median Age\").cast(FloatType())).drop(\"Median Age\") \\\n",
    "    .withColumn(\"male_population\",col(\"Male Population\").cast(IntegerType())).drop(\"Male Population\") \\\n",
    "    .withColumn(\"female_population\",col(\"Female Population\").cast(IntegerType())).drop(\"Female Population\") \\\n",
    "    .withColumn(\"total_population\",col(\"Total Population\").cast(IntegerType())).drop(\"Total Population\") \\\n",
    "    .withColumn(\"veterans_num\",col(\"Number of Veterans\").cast(IntegerType())).drop(\"Number of Veterans\") \\\n",
    "    .withColumn(\"foreign_born_population\",col(\"Foreign-born\").cast(IntegerType())).drop(\"Foreign-born\") \\\n",
    "    .withColumn(\"avg_household_size\",col(\"Average Household Size\").cast(FloatType())).drop(\"Average Household Size\") \\\n",
    "    .withColumn(\"count\",col(\"Count\").cast(IntegerType())) \\\n",
    "    .withColumnRenamed(\"City\", \"city\") \\\n",
    "    .withColumnRenamed(\"State\", \"state\") \\\n",
    "    .withColumnRenamed(\"State Code\", \"state_code\") \\\n",
    "    .withColumnRenamed(\"Race\", \"race\") \\\n",
    "    .distinct()\n",
    "                \n",
    "df_demo.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+----+-----+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+\n",
      "|city|state|state_code|race|count|median_age|male_population|female_population|total_population|veterans_num|foreign_born_population|avg_household_size|\n",
      "+----+-----+----------+----+-----+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+\n",
      "|   0|    0|         0|   0|    0|         0|              3|                3|               0|          13|                     13|                16|\n",
      "+----+-----+----------+----+-----+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Get count of both null and missing values\n",
    "df_demo.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_demo.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------------------+-----+---------------+-----------------+------------+-----------------------+------------------+\n",
      "|        city|  state|                race|count|male_population|female_population|veterans_num|foreign_born_population|avg_household_size|\n",
      "+------------+-------+--------------------+-----+---------------+-----------------+------------+-----------------------+------------------+\n",
      "|The Villages|Florida|               White|72211|           null|             null|       15231|                   4034|              null|\n",
      "|The Villages|Florida|Black or African-...|  331|           null|             null|       15231|                   4034|              null|\n",
      "|The Villages|Florida|  Hispanic or Latino| 1066|           null|             null|       15231|                   4034|              null|\n",
      "+------------+-------+--------------------+-----+---------------+-----------------+------------+-----------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show rows with null values in 'male_population' column\n",
    "df_demo.select('city','state','race','count','male_population','female_population','veterans_num','foreign_born_population','avg_household_size') \\\n",
    "    .where(col('male_population').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|race                             |\n",
      "+---------------------------------+\n",
      "|Black or African-American        |\n",
      "|Hispanic or Latino               |\n",
      "|White                            |\n",
      "|Asian                            |\n",
      "|American Indian and Alaska Native|\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check distinct values in 'race' column\n",
    "df_demo.select('race').distinct().show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pivot table to make each race population into seperate columns, change column names\n",
    "df_demo = df_demo.groupBy(col(\"city\"),col(\"state\"),col(\"median_age\") \\\n",
    "                        ,col(\"male_population\"),col(\"female_population\") \\\n",
    "                        ,col(\"total_population\"),col(\"veterans_num\") \\\n",
    "                        ,col(\"foreign_born_population\"),col(\"avg_household_size\") \\\n",
    "                        ,col(\"state_code\")) \\\n",
    "                    .pivot(\"race\").agg(sum(\"count\").cast(\"integer\")) \\\n",
    "                    .fillna({\"American Indian and Alaska Native\": 0,\n",
    "                     \"Asian\": 0,\n",
    "                     \"Black or African-American\": 0,\n",
    "                     \"Hispanic or Latino\": 0,\n",
    "                     \"White\": 0}) \\\n",
    "                    .withColumnRenamed(\"American Indian and Alaska Native\", \"american_indian_alaska_native\") \\\n",
    "                    .withColumnRenamed(\"Asian\",\"asian\") \\\n",
    "                    .withColumnRenamed(\"Black or African-American\",\"african_american\") \\\n",
    "                    .withColumnRenamed(\"Hispanic or Latino\",\"hispanic_latino\") \\\n",
    "                    .withColumnRenamed(\"White\",\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+----------+-----------------------------+-----+----------------+---------------+------+\n",
      "|      city|         state|median_age|male_population|female_population|total_population|veterans_num|foreign_born_population|avg_household_size|state_code|american_indian_alaska_native|asian|african_american|hispanic_latino| white|\n",
      "+----------+--------------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+----------+-----------------------------+-----+----------------+---------------+------+\n",
      "|   Vallejo|    California|      37.8|          58379|            62890|          121269|        8103|                  30592|              2.83|        CA|                         1671|34753|           26778|          28977| 56169|\n",
      "|   Concord|North Carolina|      35.7|          42732|            44961|           87693|        4621|                   8847|              2.72|        NC|                          216| 3566|           19027|          11301| 60500|\n",
      "|    Canton|          Ohio|      33.4|          34476|            37419|           71895|        3404|                   2204|              2.32|        OH|                          358|    0|           21353|           3597| 53571|\n",
      "| Rochester|     Minnesota|      35.0|          54934|            57282|          112216|        6888|                  17763|              2.55|        MN|                         1172| 9839|            9425|           6617| 93477|\n",
      "|Fort Worth|         Texas|      32.6|         414126|           422843|          836969|       39182|                 143404|              2.88|        TX|                         7504|42053|          167449|         296133|575180|\n",
      "+----------+--------------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+----------+-----------------------------+-----+----------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist\n",
    "if (os.path.exists(\"file:/home/workspace/demography\")\n",
    "    os.rmdir(\"file:/home/workspace/demography\")\n",
    "else:\n",
    "# write to parquet\n",
    "    df_demo.write.partitionBy('state','city').parquet('demography')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.3 Airport Code Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load airport-codes_csv.csv\n",
    "df_airport = spark.read.csv(\"airport-codes_csv.csv\",header=True,sep=\",\")\n",
    "df_airport.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count distinct countries\n",
    "df_airport.select('iso_country').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select rows for US\n",
    "df_airport.filter(df_airport.iso_country == \"US\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55075"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count rows\n",
    "df_airport.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22757"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count rows where country = US\n",
    "#df_airport.select('iso_country' == 'US').distinct().count()\n",
    "df_airport.select('iso_country').where(\"iso_country = 'US'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count distince iata_code for US\n",
    "df_airport.select('iata_code').filter(df_airport.iso_country == \"US\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20738"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count Null iata_code for US\n",
    "df_airport.where(col(\"iata_code\").isNull()).filter(df_airport.iso_country == \"US\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# delete rows with iata_code as Null, None or empty string where country == US\n",
    "df_airport = df_airport.where(\"iso_country = 'US'\") \\\n",
    "                        .filter(col('iata_code').isNotNull() | \n",
    "                        ~col('iata_code').contains('None') | \\\n",
    "                        ~col('iata_code').contains('NULL') | \\\n",
    "                            (col('iata_code') != '' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region| municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+--------------------+\n",
      "| 07FA|small_airport|Ocean Reef Club A...|           8|       NA|         US|     US-FL|    Key Largo|    07FA|      OCA|      07FA|-80.274803161621,...|\n",
      "|  0AK|small_airport|Pilot Station Air...|         305|       NA|         US|     US-AK|Pilot Station|    null|      PQS|       0AK|-162.899994, 61.9...|\n",
      "| 0CO2|small_airport|Crested Butte Air...|        8980|       NA|         US|     US-CO|Crested Butte|    0CO2|      CSE|      0CO2|-106.928341, 38.8...|\n",
      "| 0TE7|small_airport|   LBJ Ranch Airport|        1515|       NA|         US|     US-TX| Johnson City|    0TE7|      JCY|      0TE7|-98.6224975585999...|\n",
      "| 13MA|small_airport|Metropolitan Airport|         418|       NA|         US|     US-MA|       Palmer|    13MA|      PMX|      13MA|-72.3114013671999...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+------------------------------+\n",
      "|iata_code|iso_country|iso_region|municipality                  |\n",
      "+---------+-----------+----------+------------------------------+\n",
      "|ZZV      |US         |US-OH     |Zanesville                    |\n",
      "|ZPH      |US         |US-FL     |Zephyrhills                   |\n",
      "|ZNC      |US         |US-AK     |Nyac                          |\n",
      "|YUM      |US         |US-AZ     |Yuma                          |\n",
      "|YNG      |US         |US-OH     |Youngstown/Warren             |\n",
      "|YKN      |US         |US-SD     |Yankton                       |\n",
      "|YKM      |US         |US-WA     |Yakima                        |\n",
      "|YIP      |US         |US-MI     |Detroit                       |\n",
      "|YAK      |US         |US-AK     |Yakutat                       |\n",
      "|XSD      |US         |US-NV     |Tonopah                       |\n",
      "|XPR      |US         |US-SD     |Pine Ridge                    |\n",
      "|XNA      |US         |US-AR     |Fayetteville/Springdale/Rogers|\n",
      "|XMD      |US         |US-SD     |Madison                       |\n",
      "|XES      |US         |US-WI     |Lake Geneva                   |\n",
      "|WYS      |US         |US-MT     |West Yellowstone              |\n",
      "|WYB      |US         |US-AK     |Yes Bay                       |\n",
      "|WWT      |US         |US-AK     |Newtok                        |\n",
      "|WWR      |US         |US-OK     |Woodward                      |\n",
      "|WWP      |US         |US-AK     |Whale Pass                    |\n",
      "|WWD      |US         |US-NJ     |Wildwood                      |\n",
      "+---------+-----------+----------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check \"code\" and city columns to find out the relationship\n",
    "df_airport.select(col('iata_code'),col('iso_country'),col('iso_region'),col('municipality')) \\\n",
    "            .distinct().sort(df_airport.iata_code.desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split \"coordinates\" into seperate columns\n",
    "split_col = split(df_airport['coordinates'], ',')\n",
    "df_airport = df_airport.withColumn('longitude', split_col.getItem(0)) \\\n",
    "                        .withColumn('latitude', split_col.getItem(1)) \\\n",
    "                        .drop(\"coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split \"iso_region\"\n",
    "#split_region = split(df_airport['iso_region'],'-')\n",
    "#df_airport = df_airport.withColumn('region',split_region.getItem(1)) \\\n",
    "#                        .drop('iso_region') \\\n",
    " #                       .withColumnRenamed('iso_country','country') \\\n",
    "  #                      .withColumnRenamed('ident','id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+----------------+----------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region| municipality|gps_code|iata_code|local_code|       longitude|        latitude|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+----------------+----------------+\n",
      "| 07FA|small_airport|Ocean Reef Club A...|           8|       NA|         US|     US-FL|    Key Largo|    07FA|      OCA|      07FA|-80.274803161621| 25.325399398804|\n",
      "|  0AK|small_airport|Pilot Station Air...|         305|       NA|         US|     US-AK|Pilot Station|    null|      PQS|       0AK|     -162.899994|       61.934601|\n",
      "| 0CO2|small_airport|Crested Butte Air...|        8980|       NA|         US|     US-CO|Crested Butte|    0CO2|      CSE|      0CO2|     -106.928341|       38.851918|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+-------------+--------+---------+----------+----------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+---------+--------+\n",
      "|ident|type|name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|longitude|latitude|\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+---------+--------+\n",
      "|    0|   0|   0|          34|        0|          0|         0|           6|      81|        0|        50|        0|       0|\n",
      "+-----+----+----+------------+---------+-----------+----------+------------+--------+---------+----------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Get count of both null and missing values\n",
    "df_airport.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_airport.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+---------+----------+\n",
      "|ident|gps_code|iata_code|local_code|\n",
      "+-----+--------+---------+----------+\n",
      "| KZZV|    KZZV|      ZZV|       ZZV|\n",
      "| KZPH|    KZPH|      ZPH|       ZPH|\n",
      "|  ZNC|     ZNC|      ZNC|       ZNC|\n",
      "| KNYL|    KNYL|      YUM|       NYL|\n",
      "| KYNG|    KYNG|      YNG|       YNG|\n",
      "| KYKN|    KYKN|      YKN|       YKN|\n",
      "| KYKM|    KYKM|      YKM|       YKM|\n",
      "| KYIP|    KYIP|      YIP|       YIP|\n",
      "| PAYA|    PAYA|      YAK|       YAK|\n",
      "| KTNX|    KTNX|      XSD|       TNX|\n",
      "+-----+--------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check id, gps_code, iata_code, local_code and explor the relationship between those codes\n",
    "df_airport.select('ident','gps_code','iata_code','local_code').orderBy(col('iata_code').desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist\n",
    "if (os.path.exists(\"file:/home/workspace/airport\")):\n",
    "    os.rmdir(\"file:/home/workspace/airport\")\n",
    "else:\n",
    "# write to parquet\n",
    "    df_airport.write.partitionBy('iso_region').parquet('airport')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 2.4 World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|rhus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|rhus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load world temperature data\n",
    "#fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = spark.read.csv(\"../../data2/GlobalLandTemperaturesByCity.csv\",header=True,sep=\",\")\n",
    "df_temperature.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# slice table with interested columns (City, Country, Latitude and Longitude) only\n",
    "df_temperature = df_temperature.select('City','Country','Latitude','Longitude') \\\n",
    "                                .filter(df_temperature.Country == 'United States') \\\n",
    "                                .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temperature.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------+---------+\n",
      "|City|Country|Latitude|Longitude|\n",
      "+----+-------+--------+---------+\n",
      "|   0|      0|       0|        0|\n",
      "+----+-------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Get count of both null and missing values\n",
    "df_temperature.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_temperature.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# drop duplicated rows and change column names\n",
    "df_temperature = df_temperature.dropDuplicates() \\\n",
    "                                .withColumnRenamed(\"City\",\"city\") \\\n",
    "                                .withColumnRenamed(\"Latitude\",\"latitude\") \\\n",
    "                                .withColumnRenamed(\"Longitude\",\"longitude\") \\\n",
    "                                .drop(\"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+---------+\n",
      "|            city|latitude|longitude|\n",
      "+----------------+--------+---------+\n",
      "|        Columbus|  32.95N|   85.21W|\n",
      "|          Edison|  40.99N|   74.56W|\n",
      "|         Miramar|  26.52N|   80.60W|\n",
      "|Huntington Beach|  32.95N|  117.77W|\n",
      "|      Washington|  39.38N|   76.99W|\n",
      "+----------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temperature.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist and write to parquet\n",
    "if (os.path.exists(\"file:/home/workspace/coordinates\")):\n",
    "    os.rmdir(\"file:/home/workspace/coordinates\")\n",
    "else:\n",
    "    df_temperature.write.partitionBy('city').parquet('coordinates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model    \n",
    "My data modeling concept is to keep the most relevant information together in one table and reserve the most frequently requested information (from my perspective) in the fact table. In this way a lightweight fact table is produced to retrieve often needed information, in case further information is need for the analysis, joining another table (dimension table) under the Star Schema framework is also not so costly. Ideally, the dimension tables could be further normalized, a Snowflake Schema will possibly more proper considering the data integrity aspect, but it will possibly cause more costly joins among tables. After consideration, I decided on a Star Schema, specifically the fact and dimension tables look like the following:       \n",
    "\n",
    "#### Fact table\n",
    "\n",
    "__fact_immigration_record__:        \n",
    "*__cic_id (PK)__, port(FK), arrival_date, arrive_year, arrive_month, departure_date, ariline, flight_num, arrive_city (FK), arrive_state (FK), mode*\n",
    "\n",
    "#### Dimension Tables   \n",
    "1. __dim_immigrant__: *__cic_id (PK)__, age, occupation, gender, birth_year, citizen_country,resident_country*\n",
    "\n",
    "2. __dim_city__: *city, state, state_code, longitude, latitude, median_age, avg_household_size, total_population,\n",
    "male_population, female_population, veterans_num, foreign_born_population, american_indian_alaska_native, asian,african_american, hispanic_latino, white, __(city,state PK)__*\n",
    "\n",
    "3. __dim_airport__: *__id (PK)__, type, name, elevation_ft, iso_region, municipality, gps_code, iata_code (FK) reference fact_port, local_code, longitude, latitude*\n",
    "\n",
    "4. __dim_visa__: *__cic_id (PK)__, visa_type, visa_class, visa_issue_state, rrive_flag, departure_flag, update_flag, match_flag, allowed_date*\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "I used the Data Lake concept throughout the project, which is: instead of defining a strict relational structure to the data tables, I prefer to keep the database relatively flexible. For example \"null\" values were kept in the fact table, only duplicated records were excluded, because it makes no sense to exclude records with \"null\" values out of the database, considering one of the most possible important usages of the database is to keep track of every immigrant. \n",
    "\n",
    "The steps necessary to pipeline the data into the chosen data model are:\n",
    "\n",
    "1. Extract: load datasets (sas_data, demography, coordinate, airport) from the sources (parquet files stored in local/cloud after the data cleaning step)    \n",
    "\n",
    "2. Transform: selecting target columns from each data set and join them to compose fact and dimension tables  \n",
    "\n",
    "3. Load: write the final tables back to local/cloud as parquet files (I loaded back the tables directly to the Udacity provided workspace storage, for self implication on cloud self-configuration of cloud infrastructure is necessary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create fact table\n",
    "__fact_immigration_record__: *__cic_id(PK)__,port(FK),arrival_date,arrive_year,arrive_month,departure_date,ariline,flight_num,arrive_state (FK),arrive_city(FK),mode*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+------------+-----------+------------+--------------+-------+----------+------------+-----------+\n",
      "|cic_id|port|mode|arrival_date|arrive_year|arrive_month|departure_date|airline|flight_num|arrive_state|arrive_city|\n",
      "+------+----+----+------------+-----------+------------+--------------+-------+----------+------------+-----------+\n",
      "|    75| ATL|   1|  2016-04-01|       2016|           4|    2016-04-14|     LH|     00444|          TN|    Atlanta|\n",
      "|   250| NYC|   1|  2016-04-01|       2016|           4|    2016-04-08|     AA|     00101|          NY|       null|\n",
      "|   434| MIA|   1|  2016-04-01|       2016|           4|    2016-04-06|     OS|     00097|          FL|      Miami|\n",
      "|   439| MIA|   1|  2016-04-01|       2016|           4|    2016-04-09|     OS|     00097|          FL|      Miami|\n",
      "|   454| MIA|   1|  2016-04-01|       2016|           4|    2016-04-16|     OS|     00097|          FL|      Miami|\n",
      "+------+----+----+------------+-----------+------------+--------------+-------+----------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load fact table\n",
    "df_airport_temp = df_airport.select('iata_code','municipality').filter(df_airport.municipality.isNotNull())\n",
    "df_sas_temp = df_sas.select(\"cic_id\",\"port\",\"mode\",\"arrival_date\",\"arrive_year\",\"arrive_month\", \\\n",
    "                                        \"departure_date\",\"airline\",\"flight_num\",\"arrive_state\").distinct()\n",
    "cond = [df_sas_temp['port'] == df_airport_temp['iata_code']]\n",
    "fact_immigration_record = df_sas_temp.join(df_airport_temp, cond,'left').drop('iata_code') \\\n",
    "                                    .select(\"cic_id\",\"port\",\"mode\",\"arrival_date\",\"arrive_year\",\"arrive_month\", \\\n",
    "                                        \"departure_date\",\"airline\",\"flight_num\",\"arrive_state\",\"municipality\") \\\n",
    "                                    .withColumnRenamed('municipality','arrive_city') \\\n",
    "                                    .distinct()\n",
    "\n",
    "fact_immigration_record.show(5)\n",
    "fact_immigration_record.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist and write to parquet\n",
    "if (os.path.exists(\"file:/home/workspace/US_immigration\")):\n",
    "    os.rmdir(\"file:/home/workspace/US_immigration\")\n",
    "else:\n",
    "    fact_immigration_record.write.partitionBy(\"arrive_state\").parquet(\"US_immigration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create dim_immigrant\n",
    "__dim_immigrant__:    \n",
    "*__cic_id (PK)__,age,occupation,gender,birth_year,citizen_country,resident_country,arrive_state (partition key)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load dim_immigrant\n",
    "dim_immigrant = df_sas.select(\"cic_id\",\"age\",\"birth_year\",\"gender\",\"occupation\", \\\n",
    "                              \"citizen_country\",\"resident_country\",\"arrive_state\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+----------+---------------+----------------+------------+\n",
      "|cic_id|age|birth_year|gender|occupation|citizen_country|resident_country|arrive_state|\n",
      "+------+---+----------+------+----------+---------------+----------------+------------+\n",
      "|   194| 63|      1953|     M|      null|            103|             103|          CA|\n",
      "|   632| 23|      1993|     M|      null|            103|             103|          TX|\n",
      "|  1510| 68|      1948|     F|      null|            104|             104|          NY|\n",
      "|  1627| 65|      1951|     F|      null|            104|             104|          FL|\n",
      "|  1812| 45|      1971|     M|      null|            104|             104|          FL|\n",
      "+------+---+----------+------+----------+---------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immigrant.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist and write to parquet\n",
    "if (os.path.exists(\"file:/home/workspace/US_immigrant\")):\n",
    "    os.rmdir(\"file:/home/workspace/US_immigrant\")\n",
    "else:\n",
    "    dim_immigrant.write.partitionBy(\"arrive_state\").parquet(\"US_immigrant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create dim_city\n",
    "__dim_city__: \n",
    "*city, state, state_code, longitude, latitude, median_age, avg_household_size, total_population,\n",
    "male_population, female_population, veterans_num, foreign_born_population, american_indian_alaska_native, asian, african_american, hispanic_latino, white, __(city,state PK)__*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+----------+--------+---------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+-----------------------------+-----+----------------+---------------+------+\n",
      "|       city|         state|state_code|latitude|longitude|median_age|male_population|female_population|total_population|veterans_num|foreign_born_population|avg_household_size|american_indian_alaska_native|asian|african_american|hispanic_latino| white|\n",
      "+-----------+--------------+----------+--------+---------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+-----------------------------+-----+----------------+---------------+------+\n",
      "| Charleston|South Carolina|        SC|  32.95N|   79.47W|      35.0|          63956|            71568|          135524|        9368|                   5767|               2.4|                          633| 2773|           29998|           3929|104016|\n",
      "|   Savannah|       Georgia|        GA|  31.35N|   81.05W|      30.3|          69389|            76295|          145684|        9717|                  10355|              2.57|                         2116| 5366|           82307|           9734| 57690|\n",
      "|      Omaha|      Nebraska|        NE|  40.99N|   95.86W|      34.2|         218789|           225098|          443887|       24503|                  48263|              2.47|                         6318|19105|           64223|          63516|353417|\n",
      "|  Anchorage|        Alaska|        AK|  61.88N|  151.13W|      32.2|         152945|           145750|          298695|       27492|                  33258|              2.77|                        36339|36825|           23107|          27261|212696|\n",
      "|Chattanooga|     Tennessee|        TN|  34.56N|   85.62W|      36.6|          83640|            92957|          176597|       10001|                  10599|               2.4|                         1092| 4602|           59918|          10918|114140|\n",
      "+-----------+--------------+----------+--------+---------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+-----------------------------+-----+----------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load dim_city\n",
    "city_list = set(fact_immigration_record.select('arrive_city').toPandas()['arrive_city']).\n",
    "df_temp = df_temperature.selectExpr('city as temp_city','latitude','longitude')\n",
    "dim_city = df_demo.join(df_temp,df_demo.city == df_temp.temp_city, 'left') \\\n",
    "                    .select('city','state','state_code','latitude','longitude', \\\n",
    "                           'median_age','male_population','female_population', \\\n",
    "                           'total_population','veterans_num','foreign_born_population', \\\n",
    "                           'avg_household_size','american_indian_alaska_native', \\\n",
    "                           'asian','african_american','hispanic_latino','white') \\\n",
    "                    .filter(df_demo.city.isin(city_list)).distinct()\n",
    "dim_city.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist and write to parquet\n",
    "if (os.path.exists(\"file:/home/workspace/US_city\")):\n",
    "    os.rmdir(\"file:/home/workspace/US_city\")\n",
    "else:\n",
    "    dim_city.write.partitionBy(\"state_code\").parquet(\"US_city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create dim_airport\n",
    "__dim_airport__: \n",
    "*__id(PK)__, type,name, elevation_ft, continent, iso_region, municipality, gps_code, iata_code (FK, reference fact_port), local_code, longitude, latitude*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# select distinct port codes from df_sas\n",
    "port_list = set(df_sas.select('port').filter(df_sas.port.isNotNull()).toPandas()['port'])\n",
    "# load dim_airport reserving only the airport included in fact table\n",
    "dim_airport = df_airport.select('ident', 'type', 'name', 'elevation_ft', 'continent',\\\n",
    "                                'municipality', 'gps_code', 'iata_code',\\\n",
    "                                'local_code', 'longitude', 'latitude', 'iso_region') \\\n",
    "                        .filter(df_airport.iata_code.isin(port_list)) \\\n",
    "                        .filter(df_airport.municipality.isNotNull()) \\\n",
    "                        .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+--------------------+------------+---------+------------+--------+---------+----------+--------------+-------------------+----------+\n",
      "|ident|          type|                name|elevation_ft|continent|municipality|gps_code|iata_code|local_code|     longitude|           latitude|iso_region|\n",
      "+-----+--------------+--------------------+------------+---------+------------+--------+---------+----------+--------------+-------------------+----------+\n",
      "| KFWA| large_airport|Fort Wayne Intern...|         814|       NA|  Fort Wayne|    KFWA|      FWA|       FWA|  -85.19509888|        40.97850037|     US-IN|\n",
      "| KABQ| large_airport|Albuquerque Inter...|        5355|       NA| Albuquerque|    KABQ|      ABQ|       ABQ|   -106.609001|          35.040199|     US-NM|\n",
      "| KPIR|medium_airport|Pierre Regional A...|        1744|       NA|      Pierre|    KPIR|      PIR|       PIR|  -100.2860031|        44.38270187|     US-SD|\n",
      "| KFTK|medium_airport|Godman Army Air F...|         756|       NA|   Fort Knox|    KFTK|      FTK|       FTK|-85.9720993042| 37.907100677500004|     US-KY|\n",
      "| KBED|medium_airport|Laurence G Hansco...|         133|       NA|     Bedford|    KBED|      BED|       BED|  -71.28900146|        42.47000122|     US-MA|\n",
      "+-----+--------------+--------------------+------------+---------+------------+--------+---------+----------+--------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_airport.show(5)\n",
    "dim_airport.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist and write to parquet\n",
    "if (os.path.exists(\"file:/home/workspace/US_airport\")):\n",
    "    os.rmdir(\"file:/home/workspace/US_airport\")\n",
    "else:\n",
    "    dim_airport.write.partitionBy(\"iso_region\").parquet(\"US_airport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create dim_visa\n",
    "__dim_visa__: *__cic_id (PK)__, visa_type, visa_class, visa_issue_state, arrive_flag, departure_flag, update_flag, match_flag, allowed_date*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load dim_visa\n",
    "dim_visa = df_sas.select('cic_id','visa_type','visa_class','visa_issue_state','arrive_flag', \\\n",
    "                         'departure_flag','update_flag','match_flag','allowed_date') \\\n",
    "                    .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------------+-----------+--------------+-----------+----------+------------+\n",
      "|cic_id|visa_type|visa_class|visa_issue_state|arrive_flag|departure_flag|update_flag|match_flag|allowed_date|\n",
      "+------+---------+----------+----------------+-----------+--------------+-----------+----------+------------+\n",
      "|    56|       WT|         2|            null|          G|             O|       null|         M|  2016-06-29|\n",
      "|   157|       WT|         2|            null|          G|             O|       null|         M|  2016-06-29|\n",
      "|   171|       WT|         2|            null|          G|             O|       null|         M|  2016-06-29|\n",
      "+------+---------+----------+----------------+-----------+--------------+-----------+----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_visa.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove directory if already exist and write to parquet\n",
    "if (os.path.exists(\"file:/home/workspace/US_airport\")):\n",
    "    os.rmdir(\"file:/home/workspace/US_airport\")\n",
    "else:\n",
    "    dim_visa.write.partitionBy(\"visa_type\").parquet(\"US_visa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Quality checks are performed to ensure the pipeline ran as expected. These included:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+------------+-----------+------------+--------------+-------+----------+-----------+------------+\n",
      "|cic_id|port|mode|arrival_date|arrive_year|arrive_month|departure_date|airline|flight_num|arrive_city|arrive_state|\n",
      "+------+----+----+------------+-----------+------------+--------------+-------+----------+-----------+------------+\n",
      "|    69| ATL|   1|  2016-04-01|       2016|           4|    2016-04-16|     DL|     00131|    Atlanta|          FL|\n",
      "|   883| NEW|   1|  2016-04-01|       2016|           4|    2016-04-16|     UA|     02067|New Orleans|          FL|\n",
      "|  3719| NYC|   1|  2016-04-01|       2016|           4|    2016-04-02|     AA|     00065|       null|          FL|\n",
      "|  4785| CLT|   1|  2016-04-01|       2016|           4|    2016-04-23|     AA|     00787|  Charlotte|          FL|\n",
      "|  9082| MIA|   1|  2016-04-01|       2016|           4|    2016-04-11|     AF|     00090|      Miami|          FL|\n",
      "+------+----+----+------------+-----------+------------+--------------+-------+----------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- cic_id: integer (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- arrive_year: integer (nullable = true)\n",
      " |-- arrive_month: integer (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_num: string (nullable = true)\n",
      " |-- arrive_city: string (nullable = true)\n",
      " |-- arrive_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load fact table, show rows and check schema\n",
    "fact = spark.read.parquet(\"US_immigration\")\n",
    "fact.show(5)\n",
    "fact.printSchema() # check if datatypes are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count rows of fact table, row number matches the source table\n",
    "fact.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|cic_id|count|\n",
      "+------+-----+\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if \"cic_id\" are unique\n",
    "df1 = fact.groupBy(\"cic_id\").count().filter(\"count > 1\")\n",
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+----------+---------------+----------------+------------+\n",
      "|cic_id|age|birth_year|gender|occupation|citizen_country|resident_country|arrive_state|\n",
      "+------+---+----------+------+----------+---------------+----------------+------------+\n",
      "|  1804| 73|      1943|     F|      null|            104|             104|          FL|\n",
      "|  1916| 36|      1980|     M|      null|            104|             104|          FL|\n",
      "|  2175| 14|      2002|     F|      null|            105|             105|          FL|\n",
      "|  3317| 39|      1977|     M|      null|            108|             108|          FL|\n",
      "|  3718| 77|      1939|     F|      null|            108|             135|          FL|\n",
      "+------+---+----------+------+----------+---------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- cic_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- birth_year: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- citizen_country: integer (nullable = true)\n",
      " |-- resident_country: integer (nullable = true)\n",
      " |-- arrive_state: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dim_immigrant, show rows, check schema and count rows\n",
    "dim_immigrant = spark.read.parquet(\"US_immigrant\")\n",
    "dim_immigrant.show(5)\n",
    "dim_immigrant.printSchema()\n",
    "dim_immigrant.count() # row number should be equal to the fact table's row number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------+---------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+-----------------------------+------+----------------+---------------+-------+----------+\n",
      "|       city|         state|latitude|longitude|median_age|male_population|female_population|total_population|veterans_num|foreign_born_population|avg_household_size|american_indian_alaska_native| asian|african_american|hispanic_latino|  white|state_code|\n",
      "+-----------+--------------+--------+---------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+-----------------------------+------+----------------+---------------+-------+----------+\n",
      "| Charleston|South Carolina|  32.95N|   79.47W|      35.0|          63956|            71568|          135524|        9368|                   5767|               2.4|                          633|  2773|           29998|           3929| 104016|        SC|\n",
      "| Manchester| New Hampshire|  42.59N|   72.00W|      37.3|          54845|            55378|          110223|        5473|                  14506|               2.4|                          558|  4304|            6896|          11962| 100108|        NH|\n",
      "|  Charlotte|North Carolina|  34.56N|   81.73W|      34.3|         396646|           430475|          827121|       36046|                 128897|              2.52|                         8746| 55399|          301568|         113731| 446795|        NC|\n",
      "|Los Angeles|    California|  34.56N|  118.70W|      35.0|        1958998|          2012898|         3971896|       85417|                1485425|              2.86|                        63758|512999|          404868|        1936732|2177650|        CA|\n",
      "|Albuquerque|    New Mexico|  34.56N|  107.03W|      36.0|         273323|           285808|          559131|       37443|                  58200|              2.49|                        32243| 25140|           26774|         271854| 411847|        NM|\n",
      "+-----------+--------------+--------+---------+----------+---------------+-----------------+----------------+------------+-----------------------+------------------+-----------------------------+------+----------------+---------------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- median_age: float (nullable = true)\n",
      " |-- male_population: integer (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- total_population: integer (nullable = true)\n",
      " |-- veterans_num: integer (nullable = true)\n",
      " |-- foreign_born_population: integer (nullable = true)\n",
      " |-- avg_household_size: float (nullable = true)\n",
      " |-- american_indian_alaska_native: integer (nullable = true)\n",
      " |-- asian: integer (nullable = true)\n",
      " |-- african_american: integer (nullable = true)\n",
      " |-- hispanic_latino: integer (nullable = true)\n",
      " |-- white: integer (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dim_city\n",
    "dim_city = spark.read.parquet(\"US_city\")\n",
    "dim_city.show(5)\n",
    "dim_city.printSchema() # check if the datatypes are proper\n",
    "dim_city.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of distinct city in dim_city should be equal or less than in fact table\n",
    "fact.select('arrive_city').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+--------------------+------------+---------+--------------------+--------+---------+----------+-------------------+-------------------+----------+\n",
      "|ident|          type|                name|elevation_ft|continent|        municipality|gps_code|iata_code|local_code|          longitude|           latitude|iso_region|\n",
      "+-----+--------------+--------------------+------------+---------+--------------------+--------+---------+----------+-------------------+-------------------+----------+\n",
      "| KPIE|medium_airport|St Petersburg Cle...|          11|       NA|St Petersburg-Cle...|    KPIE|      PIE|       PIE|       -82.68740082|        27.91020012|     US-FL|\n",
      "| KSRQ| large_airport|Sarasota Bradento...|          30|       NA|  Sarasota/Bradenton|    KSRQ|      SRQ|       SRQ| -82.55439758300781|  27.39539909362793|     US-FL|\n",
      "| PANC| large_airport|Ted Stevens Ancho...|         152|       NA|           Anchorage|    PANC|      ANC|       ANC|-149.99600219726562| 61.174400329589844|     US-AK|\n",
      "| KSLC| large_airport|Salt Lake City In...|        4227|       NA|      Salt Lake City|    KSLC|      SLC|       SLC|-111.97799682617188|  40.78839874267578|     US-UT|\n",
      "| KRDU| large_airport|Raleigh Durham In...|         435|       NA|      Raleigh/Durham|    KRDU|      RDU|       RDU|  -78.7874984741211| 35.877601623535156|     US-NC|\n",
      "+-----+--------------+--------------------+------------+---------+--------------------+--------+---------+----------+-------------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dim_airport\n",
    "dim_airport = spark.read.parquet(\"US_airport\")\n",
    "dim_airport.show(5)\n",
    "dim_airport.printSchema() # check if the datatypes are proper\n",
    "dim_airport.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row count of dim_airport should be equal or less than the 'port' number appeared in fact table\n",
    "fact.select('port').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------+-----------+--------------+-----------+----------+------------+---------+\n",
      "|cic_id|visa_class|visa_issue_state|arrive_flag|departure_flag|update_flag|match_flag|allowed_date|visa_type|\n",
      "+------+----------+----------------+-----------+--------------+-----------+----------+------------+---------+\n",
      "|     6|         2|            null|          T|          null|          U|      null|  2016-10-28|       B2|\n",
      "|  2141|         2|             SOF|          G|             O|       null|         M|  2016-09-30|       B2|\n",
      "|  2455|         2|             KRK|          G|             O|       null|         M|  2016-09-30|       B2|\n",
      "|  2583|         2|             WRW|          G|             O|       null|         M|  2016-09-30|       B2|\n",
      "|  3682|         2|             LUA|          G|             O|       null|         M|  2016-09-30|       B2|\n",
      "+------+----------+----------------+-----------+--------------+-----------+----------+------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- cic_id: integer (nullable = true)\n",
      " |-- visa_class: integer (nullable = true)\n",
      " |-- visa_issue_state: string (nullable = true)\n",
      " |-- arrive_flag: string (nullable = true)\n",
      " |-- departure_flag: string (nullable = true)\n",
      " |-- update_flag: string (nullable = true)\n",
      " |-- match_flag: string (nullable = true)\n",
      " |-- allowed_date: date (nullable = true)\n",
      " |-- visa_type: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dim_visa\n",
    "dim_visa = spark.read.parquet(\"US_visa\")\n",
    "dim_visa.show(5)\n",
    "dim_visa.printSchema() # check if the datatypes are proper\n",
    "dim_visa.count()  # should be equal to the row count of fact table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### fact table \n",
    "Includes following columns with corresponding data types       \n",
    " |-- cic_id: integer (nullable = true)       id numbers of immigrants         \n",
    " |-- port: string (nullable = true)          three alphabetic identity codes of port through which the immigrants arrived             \n",
    " |-- mode: integer (nullable = true)         the way the immigrants arrived, 1 = 'Air', 2 = 'Sea', 3 = 'Land', 9 = 'Not reported'             \n",
    " |-- arrival_date: date (nullable = true)    the date the immigrants arrived in US            \n",
    " |-- arrive_year: integer (nullable = true)  the year the immigrants arrived in US            \n",
    " |-- arrive_month: integer (nullable = true) the month the immigrants arrived in US          \n",
    " |-- departure_date: date (nullable = true)  the date the immigrants leave US          \n",
    " |-- airline: string (nullable = true)       the name of airline the immigrants took        \n",
    " |-- flight_num: string (nullable = true)    the number of flight the immigrants tool       \n",
    " |-- arrive_city: string (nullable = true)   the city the immigrants first arrived in        \n",
    " |-- arrive_state: string (nullable = true)  the US state the immigrants first arrived in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### dim_immigrant \n",
    "Dimension table of information on immigrants, including following columns       \n",
    " |-- cic_id: integer (nullable = true) unique identity of immigrants       \n",
    " |-- age: integer (nullable = true) age of immigrants        \n",
    " |-- birth_year: integer (nullable = true) birth year of immigrants        \n",
    " |-- gender: string (nullable = true) gender of immigrants       \n",
    " |-- occupation: string (nullable = true) occupation of immigrants       \n",
    " |-- citizen_country: integer (nullable = true) three digit number indicating the citizenship country of the immigrants, country names are included in I94_SAS_Lables_Description          \n",
    " |-- resident_country: integer (nullable = true) three digit number indicating the residentship country of the immigrants, country names are included in I94_SAS_Lables_Description           \n",
    " |-- arrive_state: string (nullable = true)  the US state the immigrants first arrived, could be used as foreign combined with cic_id when joining with fact table     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### dim_city\n",
    "Includes demography information of the cities that appeared in the fact table        \n",
    "|-- city: string (nullable = true)    name of the city     \n",
    " |-- state: string (nullable = true)  state the city belongs to      \n",
    " |-- latitude: string (nullable = true)  coordinates latitude      \n",
    " |-- longitude: string (nullable = true)  coordinates longitude      \n",
    " |-- median_age: float (nullable = true)  median age of populations      \n",
    " |-- male_population: integer (nullable = true) number of male population       \n",
    " |-- female_population: integer (nullable = true) number of female population       \n",
    " |-- total_population: integer (nullable = true)  total number of population       \n",
    " |-- veterans_num: integer (nullable = true)  number of veterans      \n",
    " |-- foreign_born_population: integer (nullable = true) number of foreign_born population      \n",
    " |-- avg_household_size: float (nullable = true) average size of household        \n",
    " |-- american_indian_alaska_native: integer (nullable = true) number of population of the race as indicated in the column name               \n",
    " |-- asian: integer (nullable = true) number of population of the race as indicated in the column name        \n",
    " |-- african_american: integer (nullable = true) number of population of the race as indicated in the column name        \n",
    " |-- hispanic_latino: integer (nullable = true) number of population of the race as indicated in the column name        \n",
    " |-- white: integer (nullable = true)  number of population of the race as indicated in the column name        \n",
    " |-- state_code: string (nullable = true) state code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### dim_visa\n",
    "Dimension table with information about visa of each immigrant     \n",
    " |-- cic_id: integer (nullable = true)  unique ids of immigrants       \n",
    " |-- visa_class: integer (nullable = true) one digit integer indicating the class of visa, 1 = Business, 2 = Pleasure, 3 = Student      \n",
    " |-- visa_issue_state: string (nullable = true) the code representing the place where visa was issued   |-- arrive_flag: string (nullable = true) Arrival Flag - admitted or paroled into the U.S.       \n",
    " |-- departure_flag: string (nullable = true) Departure Flag - Departed, lost I-94 or is deceased     \n",
    " |-- update_flag: string (nullable = true) Update Flag - Either apprehended, overstayed, adjusted to perm residence        \n",
    " |-- match_flag: string (nullable = true) Match flag - Match of arrival and departure records     \n",
    " |-- allowed_date: date (nullable = true) Date to which admitted to U.S. (allowed to stay until)       \n",
    " |-- visa_type: string (nullable = true)  Class of admission legally admitting the non-immigrant to temporarily stay in U.S. Detailed description is provided in the I94_SAS_Lables_Description       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### dim_airport\n",
    "Dimension table of information about airport, including following columns \n",
    " |-- ident: string (nullable = true)  ID of airport      \n",
    " |-- type: string (nullable = true)  type of airport     \n",
    " |-- name: string (nullable = true)  name of airport      \n",
    " |-- elevation_ft: string (nullable = true) elevation of airport     \n",
    " |-- continent: string (nullable = true)  continent of airport    \n",
    " |-- municipality: string (nullable = true)  city of airport    \n",
    " |-- gps_code: string (nullable = true) gps_code of airport      \n",
    " |-- iata_code: string (nullable = true) unique iata_code of airport      \n",
    " |-- local_code: string (nullable = true) local_code of airport    \n",
    " |-- longitude: string (nullable = true) coordinates longitude\n",
    " |-- latitude: string (nullable = true)   coordinates  latitude     \n",
    " |-- iso_region: string (nullable = true) iso_region of airport      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.        \n",
    "  In princip should be updated every time a new immigrant is registered or according to the consumer demand\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.       \n",
    "  I would use Airflow or other data flow management tools to automate the ETL process. As storage, another scalable Cloud-based data lake or on-premise location would be proper. PySpark or other paralyzed frameworks would still be preferred.\n",
    " * The data populates a dashboard that must be updated daily by 7 am every day.      \n",
    " I will move the database on a Cloud platform (AWS for example) and connect with proper BI tools (Dash, Tableau for example) that are adapted to the cloud platform and automate the entire data flow using tools like Airflow.\n",
    " * The database needed to be accessed by 100+ people.     \n",
    " Deploy the database on a Cloud platform with high availability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
